{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd71ac1d",
   "metadata": {},
   "source": [
    "# NN Project, topic #4: Language identification from a text corpus\n",
    "\n",
    "Students: Shahzaib MUHAMMAD, Adriana NICOARA, Scott TANKARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631d741",
   "metadata": {},
   "source": [
    "## Our group's topic\n",
    "\n",
    "From: https://arche.univ-lorraine.fr/mod/page/view.php?id=1310565\n",
    "\n",
    "Project 4: Language identification from a text corpus\n",
    "\n",
    "Students: Scott TANKARD, Adriana NICOARA, Shahzaib MUHAMMAD\n",
    "\n",
    "Task: Text classification\n",
    "\n",
    "Model: Feedforward neural network\n",
    "\n",
    "Dataset: https://www.kaggle.com/zarajamshaid/language-identification-datasst\n",
    "\n",
    "Hint: As a preprocessing step, you should transforms the sentences into trigrams at the character level (more details at: https://towardsdatascience.com/deep-neural-network-language-identification-ae1c158f6a7d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d8f63",
   "metadata": {},
   "source": [
    "## General project instructions\n",
    "\n",
    "From: https://arche.univ-lorraine.fr/mod/page/view.php?id=1301340\n",
    "\n",
    "General project instructions\n",
    "\n",
    "Project structure\n",
    "\n",
    "Each project follows the same overall structure:\n",
    "\n",
    "    Download the data and preprocess it as required for the given task (if needed).\n",
    "    Write a Dataset class for creating the train and test datasets (and corresponding dataloaders).\n",
    "    Define the neural network model.\n",
    "    Define the hyperparameters to create an instance of the model (e.g., hidden space size, number of convolution kernels...) as well as the parameters required to train neural network (e.g., learning rate).\n",
    "    Write the training loop for training the model.\n",
    "    Evaluate the model on the test data. In this part, it is expected to choose an appropriate evaluation metric based on your task. For instance, for classification task, accuracy should be computed (but you can also search for 'precision' and 'recall').\n",
    "    Save the trained model parameters, and the obtained results if needed.\n",
    "\n",
    "\n",
    "Deliverables\n",
    "\n",
    "The project should be written using Pytorch (and not Keras/Tensorflow or any other python deep learning framework). You're expected to send a zip file containing:\n",
    "\n",
    "    A python file implementing steps 1 to 7. This can be either a jupyter notebook or a .py script. A single file is preferred, but you can use several files if that's your style, as long as your main executable script is clearly indicated (for instance it's named 'main.py').\n",
    "    The obtained results as extra files (e.g., the trained model parameters, a figure with the training loss / validation metric over epochs, a graph comparing different architectures if you want to play arround with it, etc.)\n",
    "\n",
    "Your code should be commented in order to clarify implementation details, and desciption about the inputs and outputs of functions.\n",
    "\n",
    "Note: There is no need to send the dataset, since I will download it and run your scripts directly. Therefore, make sure that you do not transform/change the raw data, and if there is some preprocessing involved, include it in your python file(s).\n",
    "\n",
    "\n",
    "General Hints\n",
    "\n",
    "    The tasks corresponding to these projects have been extensively studied. Don't hesitate to search online for more information (either tutorials or research papers, even pieces of code if you can adapt it).\n",
    "    Some datasets are very large. Therefore, you don't need to use all the data, but instead you can extract a subset of it (for instance, only a few languages for language identification, only a few images/classes for image recognition etc.) to have a lighter dataset / model / training procedure.\n",
    "    Some datasets are provided with a train / test split, but not always. Either way, you can create your own split (a good rule of thumb can be 80% training and 20 % testing).\n",
    "    It is strongly advised to use validation in order to monitor training (see 'bonus work' in lab 2.2). You can use part of the training data (e.g., 10%) as a validation set.\n",
    "    It is good practice to start with a light model (very few layers/parameters) and dataset (subset of your whole dataset) for prototyping. The performance won't be very good, but it's useful to check if there are any error in the train/test procedure. Once everything runs smoothly, you can increase the size of the model and use more data.\n",
    "    If your project includes convolutional or recurrent neural networks, don't wait the corresponding lab: you can already start working on it (you can basically do everything, just using a 'dummy' MLP model instead of a CNN/RNN).\n",
    "\n",
    "Modifi√© le: vendredi 21 octobre 2022, 12:46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3fb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Download the data and preprocess it as required for the given task (if needed).\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c71077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Write a Dataset class for creating the train and test datasets (and corresponding dataloaders).\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694e28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Define the neural network model.\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0979fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Define the hyperparameters to create an instance of the model \n",
    "# (e.g., hidden space size, number of convolution kernels...) \n",
    "# as well as the parameters required to train neural network (e.g., learning rate).\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4183f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Write the training loop for training the model.\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Evaluate the model on the test data. \n",
    "# In this part, it is expected to choose an appropriate evaluation metric based on your task. \n",
    "# For instance, for classification task, accuracy should be computed (but you can also search for 'precision' and 'recall').\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732262de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Save the trained model parameters, and the obtained results if needed.\n",
    "#########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6a96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-env-jp",
   "language": "python",
   "name": "asr-env-jp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
